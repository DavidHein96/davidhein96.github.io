{
  "hash": "5f5236129d7a493903ed305a2ac7f998",
  "result": {
    "markdown": "---\ntitle: \"Wikipedia Cancer Queries with OpenAI API & SQL\"\nauthor: \"Dave Hein\"\ndate: \"2023-07-12\"\ncategories: [Python, Natural language processing, SQL]\nimage: \"typewriter.jpg\"\nformat:\n  html: \n    toc: true\n    code-fold: show\n    code-tools: true\n---\n\n```{=html}\n<style type=\"text/css\">\n\ncode.r{\n  font-size: 14px;\n}\ntd {\n  font-size: 12px;\n}\ncode.python{\n  font-size: 14px;\n}\npre {\n  font-size: 12px;\n}\n\n</style>\n```\n\n\n# Wikipedia Cancer Query\n\nThis project was a quick exercise in data engineering, ETL, SQL, NoSQL, and text processing with OpenAI GPT-3.\n\n\n\n\n\n## Libraries\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Import libs\nimport sqlite3\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pymongo import MongoClient\nimport openai\nfrom urllib.request import urlopen\nfrom bs4 import BeautifulSoup\nimport re\nimport json\nimport ast\n```\n:::\n\n\n## Setup MongoDB Database\n\nCreate a MongoDB database and define functions to insert and query data.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Function to create MongoDB database and collection\ndef create_mongo_connection():\n    # Create a MongoDB client\n    client = MongoClient('mongodb://localhost:27017/')\n    # Connect to the \"cancerDB\" database\n    db = client['cancerDB']\n    return db\n\ndef insert_data_mongo(collection, data):\n    # Insert a document into the specified collection\n    collection.insert_one(data)\n\ndef query_data_mongo(collection, query):\n    # Find documents in the specified collection that match the query\n    results = collection.find(query)\n    return list(results)\n\n```\n:::\n\n\n## Scrape Wikipedia Pages\n\nUse urlopen to scrape the Wikipedia page for each state and store the raw text in MongoDB.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Function to scrape Wikipedia pages and store the raw text in MongoDB\ndef scrape_wikipedia_pages(cancers, db):\n    # Use the \"wikipediaText\" collection\n    wiki_text_collection = db['wikipediaText']\n    \n    base_url = \"https://en.wikipedia.org/wiki/\"\n    \n    for cancer in cancers:\n        # Create the URL for the Wikipedia page\n        url = base_url + cancer.replace(\" \", \"_\")\n        \n        # Open the URL and get the raw HTML\n        html = urlopen(url)\n        \n        # Parse the HTML with BeautifulSoup to extract the text\n        soup = BeautifulSoup(html, 'html.parser')\n        text = soup.get_text()\n        \n        # Store the text in MongoDB\n        data = {\"cancer_type\": cancer, \"text\": text}\n        insert_data_mongo(wiki_text_collection, data)\n```\n:::\n\n\n## Setup SQLite Database\n\nCreate a SQLite database and define a function to execute SQL commands.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Function to create SQLite database and table\ndef create_connection():\n    # Create a connection to the SQLite database\n    conn = sqlite3.connect('my_database.db')\n    return conn\n\ndef create_table(conn, table_name, columns):\n    # Create a table in the SQLite database\n    query = f\"CREATE TABLE {table_name} ({columns});\"\n    \n# Function to execute SQL query\ndef execute_query(conn, query):\n    # Execute the specified SQL query and print the results\n    cur = conn.cursor()\n    cur.execute(query)\n    rows = cur.fetchall()\n    for row in rows:\n        print(row)\n\n# Function to load data from OpenAI API to database\ndef load_data_to_db(conn, table_name, data):\n    # Insert the data into the specified table in the SQLite database\n    df = pd.DataFrame(data, index=[0])\n    df.to_sql(table_name, conn, if_exists='append', index=False)\n```\n:::\n\n\n## Use OpenAI API to Extract Data w/ GPT3.5\n\nUse the OpenAI API to extract structured data from the raw text of each Wikipedia page.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Function to use OpenAI API\n\ndef extract_cancer_info(text):\n    openai.api_key = api_key\n    \n    # Set up the conversation\n    messages = [\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant in a medical oncology research office.\"},\n        {\"role\": \"user\", \"content\": f\"{text}\\n\\nGiven the above text, extract the following information:\\nOne word primary cancer location as a string: \\nOne word most common metastasis site as a string: \\nTypical life expectancy for localized disease in years as a float:\\n Common Gene mutation Variants as a list of strings: \\n Whether each common mutation has a targeted therapy avaialble for this cancer as a list of booleans True or False:\\nAll Approved Drugs as a list of strings:\\n Class of each approved drug, either immunotherapy, chemotherapy, or hormonal_therapy as a list of strings:\\n Please return results in a tidy format as a python dictionary. They keys for the dictionary should be the following: primary_cancer_location, metastasis_site, life_expectancy, common_gene_mutations, targeted_therapy_available, drug_name, drug_class. Values for each key should be the corresponding value extracted from the text in the appropriate format specified above.\"}\n    ]\n    \n    # Use gpt-3.5-turbo and the openai.ChatCompletion.create method\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo-16k\",\n        messages=messages\n    )\n    \n    return response['choices'][0]['message']['content'].strip()\n\n```\n:::\n\n\n## Test Function for API Response\n\nThis ensures the response from Open AI has the correct format for loading into the SQL tables\n\n::: {.cell}\n\n```{.python .cell-code}\ndef validate_response(response_string):\n\n    # Replace \"true\" and \"false\" with \"True\" and \"False\"\n    response_string = response_string.replace(\"true\", \"True\").replace(\"false\", \"False\")\n\n    try:\n        response_dict = ast.literal_eval(response_string)\n    except (SyntaxError, ValueError):\n        raise ValueError(f\"Unable to convert response to dictionary: {response_string}\")\n\n    required_keys = [\"primary_cancer_location\", \"metastasis_site\", \"life_expectancy\", \"common_gene_mutations\", \"targeted_therapy_available\", \"drug_name\", \"drug_class\"]\n    for key in required_keys:\n        if key not in response_dict:\n            raise ValueError(f\"Missing key in response: {key}\")\n\n    # Check that the lists are of the same length\n    list_keys = [\"common_gene_mutations\", \"targeted_therapy_available\"]\n    list_lengths = [len(response_dict[key]) for key in list_keys]\n    if len(set(list_lengths)) != 1:\n        raise ValueError(\"The lists in the response are not of the same length\")\n\n    list_keys = [\"drug_name\", \"drug_class\"]\n    list_lengths = [len(response_dict[key]) for key in list_keys]\n    if len(set(list_lengths)) != 1:\n        raise ValueError(\"The lists in the response are not of the same length\")\n\n    # Check that life_expectancy is a double\n    if not isinstance(response_dict[\"life_expectancy\"], float):\n        raise ValueError(\"life_expectancy is not a double\")\n\n    # Check that the elements in the lists are of the correct type\n    if not all(isinstance(item, str) for item in response_dict[\"common_gene_mutations\"]):\n        raise ValueError(\"common_gene_mutations does not contain only strings\")\n    if not all(isinstance(item, bool) for item in response_dict[\"targeted_therapy_available\"]):\n        raise ValueError(\"targeted_therapy_available does not contain only booleans\")\n    if not all(isinstance(item, str) for item in response_dict[\"drug_name\"]):\n        raise ValueError(\"drug_name does not contain only strings\")\n    if not all(isinstance(item, str) for item in response_dict[\"drug_class\"]):\n        raise ValueError(\"drug_class does not contain only strings\")\n    \n    return response_dict\n\n```\n:::\n\n\n## ETL Process\n\nClean and transform the data, and load the data into SQLite tables.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# Start MongoDB\n#os.system(\"brew services start mongodb-community@6.0\")\ndb = create_mongo_connection()\n\n# Scrape Wikipedia pages and store the raw text in MongoDB\ncancer_types = [\"Breast cancer\", \"Lung cancer\", \"Prostate cancer\", \"Colorectal cancer\", \"Skin cancer\"]\nscrape_wikipedia_pages(cancer_types, db)\n\n# Create a connection to the SQLite database\nconn = create_connection()\n\n# Create a table for cancer types\ncreate_table(conn, \"Cancers5\", \"id INTEGER PRIMARY KEY, primary_cancer_location TEXT NOT NULL, metastasis_site TEXT, life_expectancy INT\")\n\n# Create a table for gene variants\ncreate_table(conn, \"Genes6\", \"id INTEGER PRIMARY KEY, primary_cancer_location TEXT, common_gene_mutations TEXT, targeted_therapy_available BOOLEAN\")\n\n# Create a table for drugs\ncreate_table(conn, \"Drugs5\", \"\"\"id INTEGER PRIMARY KEY, drug_name TEXT NOT NULL, drug_class TEXT CHECK( drug_class IN ('chemotherapy', 'immunotherapy', 'hormonal_therapy')), primary_cancer_location TEXT\"\"\")\n\n# Loop through each cancer type, extract data and load it into SQL tables\nfor cancer_type in cancer_types:\n\n    # Extract the raw text from MongoDB and clean it\n    text = query_data_mongo(db[\"wikipediaText\"], {\"cancer_type\": cancer_type})\n    clean_text = re.findall(r'From Wikipedia, the free encyclopedia[\\S\\s]+References', text[0]['text'])[0].replace(\"\\n\", \" \").strip()\n\n    # call the API and validate the response\n    data = extract_cancer_info(clean_text)\n    data_dict = validate_response(data)\n\n    # create a DataFrame for the cancer data\n    cancer_df =  pd.DataFrame.from_dict({\"primary_cancer_location\": [data_dict[\"primary_cancer_location\"]],\"metastasis_site\": [data_dict[\"metastasis_site\"]],\"life_expectancy\": [data_dict[\"life_expectancy\"]]})\n\n    # create a DataFrame for the gene data\n    # Create a list of tuples, where each tuple contains a mutation and its corresponding targeted therapy availability\n    mutations_data = list(zip(data_dict[\"common_gene_mutations\"], data_dict[\"targeted_therapy_available\"]))\n\n    # Create the DataFrame from the list of tuples\n    genes_df = pd.DataFrame(mutations_data, columns=[\"common_gene_mutations\", \"targeted_therapy_available\"])\n\n    # Add the cancer_type column to the DataFrame\n    genes_df[\"primary_cancer_location\"] = data_dict[\"primary_cancer_location\"]\n\n    # Same process but with the drug data\n    drugs_data = list(zip(data_dict[\"drug_name\"], data_dict[\"drug_class\"]))\n    drugs_df = pd.DataFrame(drugs_data, columns=[\"drug_name\", \"drug_class\"])\n    drugs_df[\"primary_cancer_location\"] = data_dict[\"primary_cancer_location\"]\n\n    # load dfs into the respective tables\n    cancer_df.to_sql('Cancer5', conn, if_exists='append', index=False)\n    genes_df.to_sql('Genes6', conn, if_exists='append', index=False)\n    drugs_df.to_sql('Drugs5', conn, if_exists='append', index=False)\n\n```\n:::\n\n\n## Data Querying\n\nQuery the data in the SQLite database and saving the results to a CSV file.\n\n::: {.cell}\n\n```{.python .cell-code}\n# Execute the query\ndf = pd.read_sql_query(\"\"\"\nSELECT Cancer5.primary_cancer_location, Cancer5.life_expectancy, COUNT(Genes6.targeted_therapy_available) as num_targeted_therapy\nFROM Cancer5\nLEFT JOIN Genes6 ON Cancer5.primary_cancer_location = Genes6.primary_cancer_location\nWHERE Genes6.targeted_therapy_available = 1\nGROUP BY Cancer5.primary_cancer_location;\n\"\"\", conn)\n\ndf.to_csv(\"cancer_data.csv\")\n```\n:::\n\n\n## Visualization\n\nVisualization in R because I think it is much much better than python for this purpose.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncancer_data <- read_csv(\"posts/api_and_sql/cancer_data.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\nRows: 5 Columns: 4\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(1): primary_cancer_location dbl (3): ...1, life_expectancy,\nnum_targeted_therapy\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n```\n:::\n\n```{.r .cell-code}\nggplot(cancer_data, aes(x=num_targeted_therapy,\n                        y=life_expectancy, \n                        color = primary_cancer_location)) + \n  geom_jitter(size=5, width=0.15,height=0.15, alpha =0.8) +\n  labs(x=\"Number of Genetic Variants with Approved Targeted Therapy\",\n       y=\"Life Expectancy in Years (Localized Stage)\",\n       color=\"Cancer Site\")+\n  ggtitle(\"Do Cancers With More Genes With Approved\\nTargeted Therapies Have Higher Life Expectancy?\") +\n  theme_test()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}