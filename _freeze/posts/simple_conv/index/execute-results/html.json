{
  "hash": "9ad507a7ba535431e33092990cd2fd65",
  "result": {
    "markdown": "---\ntitle: \"Basic Convolutional Neural Network For Classification\"\nauthor: \"Dave Hein\"\ndate: \"2023-06-30\"\ncategories: [Python, Deep learning]\nimage: \"beans.jpg\"\nformat:\n  html: \n    toc: true\n    code-fold: show\n    code-tools: true\n---\n\n```{=html}\n<style type=\"text/css\">\n\ncode.r{\n  font-size: 14px;\n}\ntd {\n  font-size: 12px;\n}\ncode.python{\n  font-size: 14px;\n}\npre {\n  font-size: 12px;\n}\n\n</style>\n```\n\n## Introduction\n\nThis is code I originally wrote for an assignment in my deep learning class. In order to post it on my public facing portfolio I've made several alterations and have changed the data set. The new data set I'm using is the \"beans\" data set from Hugging Face. This data set contains images of bean plant leaves with either no disease, Bean Rust, or Angular Leaf Spot. The leaf below has Bean Rust, identified by the small brown spots.\n\n![](bean_rust_test.jpg){fig-align=\"center\" width=\"244\"}\n\n## Code\n\n### Load Libraries\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom datasets import load_dataset, Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision.transforms import Compose, ColorJitter, ToTensor, Resize, RandomHorizontalFlip, RandomVerticalFlip, RandomRotation, RandomAffine\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport torch\nfrom time import time\nimport torch.utils.tensorboard as tb\nimport torch.nn.functional as F\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nfrom torch import save\nfrom os import path\n```\n:::\n\n\n### Make Data set Class\n\nHere I turn the Hugging Hace data set into a PyTorch data set, which plays better with my previous CNN model and training set up. I perform a good amount of data augmentation including random flips and rotations, as well as jittering the brightness and contrast.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Inherits from pytorch datasets\nclass MyDataset(Dataset):\n    def __init__(self, data_path, train=True):\n        \n        # Only perform augmentation on the train data\n        if train:\n            self.dataset = load_dataset(\"imagefolder\", data_dir=data_path, drop_labels=False, split=\"train\")\n            self.dataset = self.dataset.map(self.img_resize, remove_columns=[\"image\"], batched=True)\n            # Here `set_transforms` performs the transforms on the fly to save memory (doesnt cache)\n            self.dataset.set_transform(self.transforms)\n            \n        # the valid/test data only gets turned into a pytorch tensor\n        else:\n            self.dataset = load_dataset(\"imagefolder\", data_dir=data_path, drop_labels=False, split=\"test\")\n            self.dataset = self.dataset.map(self.img_resize, remove_columns=[\"image\"], batched=True)\n            self.dataset.set_transform(self.test_transform)\n\n    def transforms(self, imgs):\n        augment = Compose([\n                            RandomHorizontalFlip(p=0.5), \n                            RandomVerticalFlip(p=0.5),\n                            ColorJitter(brightness=0.1,\n                                        contrast=0.1,\n                                        saturation=0.1,\n                                        hue=0),\n                                RandomRotation(degrees=45),\n                                RandomAffine(degrees=10),\n                                ToTensor()\n                            ])\n        imgs[\"pixel_values\"] = [augment(image) for image in imgs[\"pixel_values\"]]\n        return imgs\n\n    def test_transform(self, imgs):\n        augment = Compose([ToTensor()])\n        imgs[\"pixel_values\"] = [augment(image) for image in imgs[\"pixel_values\"]]\n        return imgs\n    \n    \n    def img_resize(self, imgs):\n        # Resize the images to save on memory usage\n        imgs[\"pixel_values\"] = [image.convert(\"RGB\").resize((100,100)) for image in imgs[\"image\"]]\n        return imgs\n\n    def __getitem__(self, index):\n        data = self.dataset[index]\n        # Make the labels one hot tensors w/data type float\n        label = F.one_hot(torch.tensor(data[\"label\"]), num_classes=3)\n        return data[\"pixel_values\"], label.float()\n\n    def __len__(self):\n        return len(self.dataset)\n\n#img = bean_data_train[0][\"pixel_values\"]\n#plt.imshow(np.transpose(img, (1,2,0)))\n```\n:::\n\n\n### Build the CNN\n\nHere I build a pretty simply CNN with an initial layer with kernel size 7. The following layers can be added as \"Blocks\" for easy customization of channel numbers and network depth.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\"\"\"\nCNN class\n - Can take layers argument to define number of channels and depth\n - Number of input channels will always be 3\n - Currently the first layer is hardcoded with kernel size 7, and stride 2\n    I think this should be reduced to 5 or even 3.\n - The class Block defines a block of 2 conv layers. This could be extended to 3\n    and include a skip. Could also include params for kernal size and striding\n - Normalization is performed here instead of in Utils, I randomly entered the mean and sdev so this may impact performance on the bean data set\n\"\"\"\n\nclass ConvoClassifier(torch.nn.Module):\n\n    class Block(torch.nn.Module):\n        def __init__(self, n_input, n_output, stride=1):\n            super().__init__()\n\n            # Defines a two layer block with stride in first layer only, batch norm after each\n            self.net = torch.nn.Sequential(\n                # Only the first layer is strided, can adjust this in the loop in the init method\n                torch.nn.Conv2d(n_input, n_output, kernel_size=3,\n                                padding=1, stride=stride),\n                torch.nn.ReLU(),\n                torch.nn.Conv2d(n_output, n_output, kernel_size=3, padding=1),\n                torch.nn.BatchNorm2d(n_output),\n                torch.nn.ReLU()\n            )\n\n        def forward(self, x):\n            return self.net(x)\n\n    def __init__(self, layers=[32, 64, 128], n_input_channels=3, n_classes=3):\n        super().__init__()\n        # Inital layer with kernal size 7, the max pool appears to increase accuracy on validation set\n        L = [torch.nn.Conv2d(n_input_channels, layers[0], kernel_size=7, padding=3, stride=2),\n             torch.nn.ReLU(), torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)]\n        c = layers[0]\n        # Build network from list of layers\n        for l in layers:\n            # can adjust stride here\n            L.append(self.Block(c, l, stride=2))\n            c = l\n\n        self.network = torch.nn.Sequential(*L)\n        # Linear layer at end for the 3 classification labels\n        self.classifier = torch.nn.Linear(c, n_classes)\n        # Mean and standard dev of color channels accross the entire training set\n        self.norm = torchvision.transforms.Normalize(\n            mean=[0.233, 0.298, 0.256], std=[0.199, 0.118, 0.201])\n\n    def forward(self, x):\n        # Normalize\n        normx = self.norm(x)\n        # Compute the features\n        z = self.network(normx)\n        # Global average pooling\n        z = z.mean(dim=[2, 3])\n        # Classify\n        return self.classifier(z)\n\n# Save the model with epoch number and message/name of model (for checkpoints)\ndef save_model(model, message, epoch):\n    name = message + '_' + str(epoch) + '_' + 'det.th'\n    from torch import save\n    from os import path\n    return save(model.state_dict(), path.join(path.dirname(path.abspath(__file__)), name))\n\ndef load_model(model_name):\n    from torch import load\n    from os import path\n    r = ConvoClassifier()\n    r.load_state_dict(load(path.join(path.dirname(\n        path.abspath(__file__)), model_name), map_location='cpu'))\n    return r\n```\n:::\n\n\n### Train the Model\n\nThe main training loop with arguments that can be passed through the command line. I use tensor board to monitor training loss and validation accuracy.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n#from .models import ConvoClassifier, save_model, load_model\n#from .utils import MyDataset\n\n\"\"\"\nRunning tensorboard\n - launch terminal w/deeplearning virual env\n - run python -m tensorboard.main --logdir=runs\n - open in browser\n - enabels visualization of training loss and accuracy after each batch\n    and validation accuracy after each epoch\n\"\"\"\n\n\"\"\"\nMain training loop\n - Takes training arguments\n    - log_dir: directory of logs for tensorboard\n    - run_info: short description of run for identification in tensorboard\n    - lr: learning rate\n    - ep: number of epochs\n    - layers: takes multiple int values and constructs a list used for construction of model. \n        Each number is number of channels and length of list is number of layers\n\n - Prints time and validation accuracy to consol after each epoch. Saves model at end\n - Note: each \"layer\" is a block of 2 convolutional layers, see models.py\n - Should add ability to customize learning rate schedule, currently decaying around \n    6 epochs gives good results \n\"\"\"\n\ndef load_data(dataset_path, num_workers=0, batch_size=256, train=True):\n    dataset = MyDataset(dataset_path, train)\n    return DataLoader(dataset, num_workers=num_workers, batch_size=batch_size, shuffle=True, drop_last=True)\n\ndef train(args):\n\n    start = time()\n    # model constructed here\n    model = ConvoClassifier(args.layer_list, args.num_classes).to(device)\n\n    # set up logger with the run info name\n    train_logger, valid_logger = None, None\n    if args.log_dir is not None:\n        train_dir = \"train\" + args.run_info\n        valid_dir = \"valid\" + args.run_info\n        train_logger = tb.SummaryWriter(path.join(args.log_dir, train_dir))\n        valid_logger = tb.SummaryWriter(path.join(args.log_dir, valid_dir))\n\n    # Choice of optimizer, adam working better so far\n    # optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n    optimizer = torch.optim.Adam(model.parameters(), lr=args.learn_rate)\n\n    # LR scheduler, will want to eventually add ability to customize args for this\n    scheduler = torch.optim.lr_scheduler.StepLR(\n        optimizer, step_size=6, gamma=0.2)\n    step = 0\n\n    train_data = load_data(args.data_dir,0,args.batch_size,True)\n    val_data = load_data(args.data_dir,0,args.batch_size,False)\n\n    # Main loop\n    for epoch in range(args.num_epochs):\n        startepoch = time()\n        total_loss = 0\n\n        # Make sure things are set to training mode\n        model.train()\n        for i, (x, y) in enumerate(train_data):\n\n            x = x.to(device)\n            y = y.to(device)\n            output = model(x)\n            l = F.cross_entropy(output, y)\n            optimizer.zero_grad()\n            l.backward()\n            optimizer.step()\n            total_loss += l\n\n            # compute accuracy on training batch, need to get it back to CPU and change to numpy array\n            acc = (output.argmax(1).type_as(y) ==\n                   y.argmax(1)).float().detach().cpu().numpy()\n            acc = np.mean(acc)\n\n            train_logger.add_scalar(\"Loss\", l, global_step=step)\n            #train_logger.add_scalar(\"acc\", acc, global_step=step)\n            step += 1\n\n        # Test model on validation set after training epoch, make sure to set to eval mode\n        model.eval()\n        val_acc = np.array([])\n        for i, (x, y) in enumerate(val_data):\n            x = x.to(device)\n            y = y.to(device)\n            output = model(x)\n            # compute accuracy on validation set, need to get it back to CPU and change to numpy array\n            acc = (output.argmax(1).type_as(y) ==\n                   y.argmax(1)).float().detach().cpu().numpy()\n            acc = np.mean(acc)\n            val_acc = np.append(val_acc, acc)\n           \n        valid_logger.add_scalar(\n            \"val_acc_epoch\", np.mean(val_acc), global_step=step)\n       \n        # End of epoch, print validation accurcy and epoch time\n        endepoch = time()\n        scheduler.step()\n        print(np.mean(val_acc))\n        print(\"epochtime\", endepoch-startepoch)\n\n    # print total time of model and save\n    end = time()\n    print(\"total time\", end-start)\n    save_model(model, args.run_info, args.num_epochs)\n\n\"\"\"\nArguments:\n - log_dir: directory of logs for tensorboard\n - run_info: short description of run for identification in tensorboard\n - lr: learning rate\n - ep: number of epochs\n - layers: takes multiple int values and constructs a list used for construction of model. \n    Each number is number of channels and length of list is number of layers\n\"\"\"\n\nif __name__ == '__main__':\n    import argparse\n\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument('--log_dir', default='runs')\n    parser.add_argument('-n', '--run_info', type=str)\n    parser.add_argument('-lr', '--learn_rate', type=float, default=0.0001)\n    parser.add_argument('-ep', '--num_epochs', type=int, default=4)\n    # layer list requires at least one number. Multiple numbers seperated by a single space\n    parser.add_argument('-layers', '--layer_list', nargs='+',\n                        type=int, default=[32, 64, 128])\n    parser.add_argument('-data', '--data_dir', type=str, default='../../beans')\n    parser.add_argument('-c', '--num_classes', type=int, default=3 )\n    parser.add_argument('-bs', '--batch_size', type=int, default=256)\n\n    args = parser.parse_args()\n    train(args)\n```\n:::\n\n\n## Results\n\n### Command line calls\n\nI try training two models with different numbers of channels in each layer. Which will perform better?\n\n`python -m run_beans -n small_model -bs 128 -ep 12 -layers 32 64 128`\n\n`python -m run_beans -n big_model -bs 128 -ep 12 -layers 64 128 256`\n\n### Training Loss\n\nMy initial results didn't seem too bad! This was done with a very minimal amount of \"Graduate student descent\" so the model has a ton of room for improvement.\n\nThe smaller model is in orange and the larger model is in purple. The larger model has lower training loss after 12 epochs but does it have better accuracy?\n\n![](tensorboard_key.jpg){fig-align=\"center\" width=\"225\"}\n\n![](training_loss.jpg){fig-align=\"center\" width=\"850\"}\n\n### Validation Accuracy\n\nHere the larger model is in green and the smaller model is in grey. Looks like the larger model is a bit better! However after about 9 epochs the accuracy starts to plateu. I'd want to do some graduate student descent to get that accuracy up (But not push it too hard as I don't want to over fit to the validation set). Also, if this were a more serious project I'd need to have a hold out test set that I only try at the very end of training. (No peeking!)\n\n![](vall_acc.jpg){fig-align=\"center\" width=\"850\"}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}